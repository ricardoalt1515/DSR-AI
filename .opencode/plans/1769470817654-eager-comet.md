# Análisis: Document Analysis Agent

## Objetivo del Agente

Extraer información estructurada de documentos (PDFs, imágenes) para el intake de waste-assessment. Convierte documentos no estructurados en datos tipados que alimentan el cuestionario de evaluación.

## Arquitectura

```
Upload API → Worker (polling) → IngestionService → DocumentAnalysisAgent → DB persistence
```

## Componentes Clave

### 1. Agent (`document_analysis_agent.py`)
- **Framework**: `pydantic_ai.Agent`
- **Modelo**: `openai:gpt-5-mini` (configurable via `AI_DOCUMENT_MODEL`)
- **Output tipado**: `DocumentAnalysisOutput`
- **Settings**: `temperature=0.2`, `retries=2`
- **Dependencias runtime**: `DocumentContext(filename, doc_type, field_catalog)`

### 2. Output Schema (`document_analysis_output.py`)
```python
DocumentAnalysisOutput:
  - summary: str
  - key_facts: list[str]
  - suggestions: list[DocumentSuggestion]  # field_id, value, unit, confidence, evidence
  - unmapped: list[DocumentUnmapped]       # extracted_text, confidence
```

### 3. Prompt (`document-analysis.md`)
- Rol: extraction agent para waste-assessment
- Reglas: no inventar valores, evidencia con page+excerpt, confidence 0-100
- Tipos: `sds` (safety data), `lab` (lab reports), `general`
- Cap: máximo 10 unmapped items

### 4. Inyección Dinámica de Instrucciones
```python
@document_analysis_agent.instructions
def inject_doc_type(ctx): ...    # Inyecta tipo de documento
def inject_field_catalog(ctx): ... # Inyecta campos permitidos
```

## Flujo de Ejecución

1. **API** recibe archivo → crea `ProjectFile` con `processing_status="queued"`
2. **Worker** poll DB → claim file con `SELECT FOR UPDATE SKIP LOCKED`
3. **IngestionService** descarga archivo → rutea por tipo:
   - PDF → `_process_document()`
   - JPG/PNG photos → `_process_image()`
   - JPG/PNG docs → `_process_document()`
4. **Agent** ejecuta con documento binario + contexto
5. **Persistence** guarda `IntakeSuggestion` + `IntakeUnmappedNote`

## Archivos Relacionados

| Archivo | Propósito |
|---------|-----------|
| `app/agents/document_analysis_agent.py` | Definición del agente |
| `app/models/document_analysis_output.py` | Schema de salida |
| `app/prompts/document-analysis.md` | System prompt |
| `app/services/intake_ingestion_service.py` | Orquestador del pipeline |
| `scripts/intake_ingestion_worker.py` | Worker de background |

## Observaciones para Mejoras

### Potenciales Issues
1. **Error handling básico** - solo captura genérico `Exception`
2. **Sin retry inteligente** - `retries=2` es fijo sin backoff
3. **Sin métricas/telemetría** - solo logging básico
4. **field_catalog como string** - no estructurado
5. **Sin validación de media_type** - asume PDF válido
6. **Sin timeout explícito** - depende del default del SDK

### Posibles Mejoras
- [ ] Structured error types (rate limit, invalid doc, etc.)
- [ ] Retry con exponential backoff
- [ ] Métricas de latencia/tokens/success rate
- [ ] Validación de documento antes de enviar a LLM
- [ ] Cache de resultados por hash
- [ ] Streaming para documentos largos
- [ ] Fallback model si principal falla

---

## Próximos Pasos

Esperando input del usuario sobre qué aspecto quiere mejorar:
1. Error handling y resiliencia
2. Observabilidad (métricas, tracing)
3. Performance (caching, streaming)
4. Validación y seguridad
5. Otro aspecto específico
