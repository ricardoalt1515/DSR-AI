# Implementation Tasks (Executable)

> Objetivo: implementar Archive/Restore/Purge para `Company`, `Location`, `Project` con aislamiento multi-tenant, read-only real, cascadas seguras, concurrencia sin carreras y cleanup de storage. UI/UX al final (para diseñador).

## Status (as-is, ya implementado vs pendiente)

✅ Ya funciona (alto nivel)
- Backend: archive/restore/purge (Company/Location/Project) + cascadas + scoping multi-tenant + RBAC + locks + filtros `archived=active|archived|all` en list/stats/detail + counts consistentes.
- Backend: storage deletion hardening (local + S3) con allowlist `projects/|proposals/` + checks anti-traversal + deletes best-effort post-commit.
- Backend: local storage canónico sin capa extra `/uploads` (keys relativas `projects/...`, `proposals/...`; URLs locales `/uploads/{key}`).
- Frontend: toggle `archived` (dashboard + companies) + banners “Archived” + dialogs (archive/restore/purge) + read-only completo en tabs (files/proposals/technical data) cuando `archivedAt` existe.
- Frontend: dashboard stats respetan `archived` + pipeline usa `pipelineStages` (sin double-count).
- Frontend: “Delete vs Archive” alineado (acciones visibles: Archive + Purge; no “Delete” engañoso).
- Frontend: `bun run check:ci` incluye `bun run build` (gate de TypeScript/Next build).

⚠️ Aún pendiente (enfocar aquí)
- Backend: `make check` aún falla por `ty check` (baseline en `app/agents/*` + algunos diagnósticos nuevos por typing SQLAlchemy). Definir si “P0 para merge” es arreglar TODO `ty` o separar baseline con un plan de reducción gradual.
- Backend tests: en este entorno sandbox faltan temp dirs/permissions (pytest falla); validar en tu entorno real o docker y ajustar runner/fixtures si CI lo exige.

⚠️ Nota sobre verificación
- En este entorno sandbox, pytest puede fallar por temp dirs/permissions; no asumir “tests verdes” hasta correr en tu entorno real o docker/CI.

## Backend + DB (bloqueante)

1) Alembic migration: columnas + FKs + índices
- Add columns:
  - `companies`: `archived_at`, `archived_by_user_id` (FK users, `ON DELETE SET NULL`)
  - `locations`: `archived_at`, `archived_by_user_id` (FK users), `archived_by_parent_id` (FK companies, `ON DELETE SET NULL`)
  - `projects`: `archived_by_user_id` (FK users), `archived_by_parent_id` (FK locations, `ON DELETE SET NULL`)
    - No crear `projects.archived_at` (ya existe).
- Índices:
  - `companies`: `(organization_id, archived_at)`
  - `locations`: `(organization_id, archived_at)` y `(organization_id, archived_by_parent_id)`
  - `projects`: `(organization_id, archived_at)` y `(organization_id, archived_by_parent_id)`
- Acceptance:
  - Migración aplica clean en DB existente.
  - No rompe despliegue con `projects.archived_at` ya presente.

2) Actualizar ORM models (Company/Location/Project)
- `backend/app/models/company.py`: agregar columnas nuevas.
- `backend/app/models/location.py`: agregar columnas nuevas.
- `backend/app/models/project.py`: mapear `archived_at` existente + agregar columnas nuevas.
- Acceptance:
  - ORM refleja exactamente esquema DB.

3) Actualizar schemas Pydantic (backend)
- Exponer en reads (summary/detail): `archivedAt`, `archivedByUserId` (y `archivedByParentId` donde aplique).
- No exponer campos archive en create/update normales (solo vía endpoints archive/restore).
- Acceptance:
  - FE puede renderizar banner “Archived”.

4) Dependencies de acceso + “Active*Dep” (read-only enforcement)
- `backend/app/api/dependencies.py`:
  - `ActiveProjectDep`: (Project access) + `require_not_archived(project)`
  - `ActiveLocationDep`: (Location access + RBAC) + `archived_at IS NULL`
  - `ActiveCompanyDep`: (Company access + RBAC) + `archived_at IS NULL`
- Acceptance:
  - Todas las rutas write migran a `Active*Dep` sin duplicar checks.

5) RBAC deps para archive/restore/purge
- Company/Location:
  - archive/restore/purge: solo `org_admin/superuser`
- Project:
  - archive/restore: owner (`project.user_id`) OR `org_admin/superuser`
  - purge: solo `org_admin/superuser`
- Acceptance:
  - Tests de RBAC cubren cada endpoint.

6) Query param de archivado (no choca con business `status=`)
- List endpoints: `archived=active|archived|all` (default `active`)
- Mantener `status=` como filtro de business-status (projects).
- Stats/dashboard: mismo `archived=` (default active).
- Acceptance:
  - Default no incluye archivados.
  - `archived=archived|all` funciona en list + stats.

7) Endpoints canónicos + compat (archive)
- Canonical:
  - `POST /companies/{id}/archive`
  - `POST /companies/locations/{id}/archive`
  - `POST /projects/{id}/archive`
- Compat (deprecable):
  - `DELETE /companies/{id}` → llama a archive
  - `DELETE /companies/locations/{id}` → llama a archive
  - `DELETE /projects/{id}` → llama a archive
- Restore:
  - `POST /companies/{id}/restore`
  - `POST /companies/locations/{id}/restore`
  - `POST /projects/{id}/restore`
- Purge (POST, porque FE delete no manda body):
  - `POST /companies/{id}/purge`
  - `POST /companies/locations/{id}/purge`
  - `POST /projects/{id}/purge`
  - Body: `{"confirm_name": "exact-entity-name"}` (trim, case-sensitive)
- Status codes:
   - archive/restore: `200 {message}` idempotente (no pisa auditoría)
   - purge: `204` ok; `404` si no existe; `409` si no archived; `400` si confirm_name falta o no matchea
- Acceptance:
  - Contrato consistente en Company/Location/Project.

8) Cascade archive/restore (bulk + no clobber manual)
- Reglas de mutación:
  - Manual archive: `archived_at=now`, `archived_by_user_id=user`, `archived_by_parent_id=NULL`
  - Cascade archive: solo si `archived_at IS NULL`; set `archived_at=now`, `archived_by_user_id=user`, `archived_by_parent_id=parent.id`
  - Restore: set `archived_at=NULL`, `archived_by_user_id=NULL`, `archived_by_parent_id=NULL`
- Company archive:
  - Archive company.
  - Bulk `UPDATE locations ... WHERE org AND company_id=:id AND archived_at IS NULL`
  - Bulk `UPDATE projects ... WHERE org AND location_id IN (company locations) AND archived_at IS NULL`
- Company restore (top-down):
  - Restore company.
  - Restore locations con `archived_by_parent_id=company.id`.
  - Para cada location restaurada, restore projects con `archived_by_parent_id=location.id`.
- Location archive/restore análogo (projects).
- Acceptance:
  - Manual archives no se pisan.
  - Restore no revive hijos fuera de esa cascada.

9) Concurrencia (locks cortos, sin deadlocks)
- Regla de orden:
  - Lock top-down (Company → Location → Project)
  - Dentro de cada set: `ORDER BY id`
- Usar `with_for_update()` solo en sección crítica (DB mutations).
- Nunca sostener locks durante IO largo (IA/S3): re-check + lock justo antes de persist.
- Acceptance:
  - No hay carrera “write después de archive”.

10) Read-only enforcement (migrar rutas write a Active deps)
- `backend/app/api/v1/project_data.py`: `ProjectDep` → `ActiveProjectDep`
- `backend/app/api/v1/files.py`: `ProjectDep` → `ActiveProjectDep` (upload/delete)
- `backend/app/api/v1/proposals.py`:
  - generate/persist: `ActiveProjectDep`
  - delete proposal/file: bloquear si archived (usar Active dep o guard equivalente)
- `backend/app/api/v1/projects.py`:
  - `PATCH` bloqueado si archived
  - `POST /projects` valida `location_id` via `ActiveLocationDep`
- `backend/app/api/v1/companies.py`:
  - updates: `ActiveCompanyDep`
  - location updates + contacts CRUD: `ActiveLocationDep`
- Acceptance:
  - Ninguna ruta write permite tocar archived (incluye deletes de files/proposals).

11) Purge storage cleanup (bulk collect)
- Semántica:
  - Collect keys BEFORE delete DB
  - Delete DB (commit)
  - Delete storage best-effort + logs
- Project purge:
  - Collect `project_files.file_path`
  - Collect `proposals.pdf_path` (+ extras en `ai_metadata.pdfPaths` si existen)
- Location/Company purge:
  - Bulk collect keys vía joins por `org` + `location_id`/`project_id` (evitar N+1)
- Añadir script/cron de limpieza de orphans (aceptado).
- Acceptance:
  - Purge limpia DB y hace cleanup best-effort sin romper transacción.

12) Tests (pytest)
- Casos mínimos:
  - filtros `archived` en list + stats (default/archived/all)
  - archive/restore idempotentes no pisan auditoría
  - purge: 400 si confirm_name falta/no matchea; 409 si no archived; 404 si no existe; 204 si ok
  - RBAC (owner vs admin) + multi-tenant isolation
  - read-only: write endpoints devuelven 409 cuando archived
- Acceptance:
  - Tests cubren flows críticos (aunque el runner local requiera PYTHONPATH/docker).

## Frontend (API plumbing) (bloqueante mínimo; UI al final)

13) API clients: soportar `archived=` y acciones
- `frontend/lib/api/projects.ts`:
  - agregar query param `archived=` en `getProjects` y `getStats`
  - agregar métodos `archiveProject`, `restoreProject`, `purgeProject(confirm_name)`
- `frontend/lib/api/companies.ts`:
  - agregar query param `archived=` en list companies/locations
  - agregar métodos `archiveCompany`, `restoreCompany`, `purgeCompany(confirm_name)`
  - agregar métodos `archiveLocation`, `restoreLocation`, `purgeLocation(confirm_name)`
- Acceptance:
  - FE puede disparar archive/restore/purge sin cambios de layout.

## UI/UX (para diseñador; al final)

14) Toggles “Archived: Active | Archived | All”
- DONE: Companies list, Company detail (locations), Dashboard (projects list).
- TODO: Location detail (projects list) si se requiere ver archived/all ahí.

15) Banner + read-only en detail
- DONE (parcial): Company/Location/Project banner + actions según permisos.
- TODO: read-only completo en Project tabs (proposals/files/etc.) para evitar UX “backend rechaza con 409”.

16) Dialogs
- Archive: copy reversible.
- Purge (admin): input confirm_name + resumen de impacto (counts si es posible).

---

## P0 (must): Storage deletion safety (local + S3)

Objetivo: borrar SOLO archivos/keys dentro de un scope permitido. Evitar path traversal (local) y deletes fuera de prefixes permitidos (S3).

1) Decisión (ya tomada): DB guarda SOLO keys relativas (ej. `projects/...`, `proposals/...`). No paths absolutos.

2) Crear helper único (choke point) para validación + borrado (DONE)
- `backend/app/services/storage_delete_service.py`

3) Reemplazar borrado ad-hoc por helper (DONE)
- `backend/app/api/v1/projects.py` (purge)
- `backend/app/api/v1/companies.py` (purge)
- `backend/app/api/v1/proposals.py` (delete proposal/PDF)
- `backend/app/api/v1/files.py` (delete + cleanup)

4) Tests mínimos de seguridad (DONE)
- `backend/tests/test_storage_delete_service.py`

## New P0: Local URL correctness + defense-in-depth

✅ DONE: Local proposal PDF URLs are `/uploads/proposals/...` (no double `uploads/`).
- `backend/app/services/s3_service.py` canonical local root
- `backend/app/main.py` static mount

2) Defense-in-depth: enforce allowlist in low-level storage functions
- ✅ DONE: `backend/app/services/s3_service.py` `delete_file_from_s3()` valida key allowlisted
- ✅ DONE: `backend/app/services/s3_service.py` `upload_file_to_s3()` (local mode) valida key antes de escribir

## New P0: Frontend build gate + crash

1) Fix `project-card.tsx` undefined identifier
- ✅ DONE: `frontend/components/features/dashboard/components/project-card.tsx`: eliminado/fijado `isDeleting`

2) Make `check:ci` run `next build`
- ✅ DONE: `frontend/package.json`: `check:ci = biome ci ./ && bun run build`

---

## P1: UX correctness (archived filter + read-only)

1) Dashboard stats deben respetar el filtro `archived`
- ✅ DONE

2) Project pipeline no debe double-count
- ✅ DONE

3) Read-only completo en Project UI
- ✅ DONE (tabs principales + mensajes/disable actions)

---

## Remaining Work (para el LLM implementador)

1) Backend: decidir política para `ty check` (P0 vs follow-up)
- Opción A (recomendada si CI lo exige): arreglar `ty` hasta 0 errores, empezando por:
  - `backend/app/agents/image_analysis_agent.py` y `backend/app/agents/proposal_agent.py` (returns mal tipados / atributos en `str`).
  - Luego reducir ruido SQLAlchemy: tipar `OrganizationContext.id`/`org.id` como `UUID` (o cast puntual) para evitar `Unknown | Column[UUID]` en endpoints como `backend/app/api/v1/companies.py`.
- Opción B (si CI aún no bloquea): documentar baseline existente y abrir tarea separada “ty cleanup sprint”.

2) Backend tests: correr en entorno real/docker y documentar comando “source of truth”
- Confirmar `cd backend && make check` en tu entorno (no sandbox).
- Si pytest falla por temp dirs/logging: fijar `TMPDIR`/`PYTHONPATH` o ajustar config/fixtures para que CI sea determinístico.
