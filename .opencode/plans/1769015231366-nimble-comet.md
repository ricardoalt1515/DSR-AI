# Plan Review: Delete/Archive/Purge Policy

## Final Verdict: ✅ APPROVED (with refinements)

Reviewed by: code-simplifier, libraryan, explore agents

---

## Summary

Original plan is solid. Author accepted all recommended refinements:

| Original | Refined |
|----------|---------|
| `is_archived` + `archived_at` | Only `archived_at` (NULL = active) |
| `archived_reason: str` | `archived_by_parent_id: UUID \| NULL` |
| `DELETE /x` semantics | Keep `DELETE /x` = archive (FE compat) + add `POST /x/archive` (best-practice path); purge separate endpoint |
| 3 separate guards | Single `require_not_archived(entity)` |

---

## Approved Design

### Data Model

**No genérico — FK específico por tabla:**

```python
# Company: no tiene parent (siempre NULL o no incluir el campo)
class Company(Base):
    archived_at: datetime | None
    archived_by_user_id: UUID | None  # FK users

# Location: parent es Company
class Location(Base):
    archived_at: datetime | None
    archived_by_user_id: UUID | None  # FK users
    archived_by_parent_id: UUID | None  # FK companies, ON DELETE SET NULL

# Project: parent es Location
class Project(Base):
    archived_at: datetime | None
    archived_by_user_id: UUID | None  # FK users
    archived_by_parent_id: UUID | None  # FK locations, ON DELETE SET NULL
```

**Índices:**
- Filtrado: `(organization_id, archived_at)` — queries principales
- Restore cascade: `(organization_id, archived_by_parent_id)` — en `locations` y `projects`
- Partial unique: `WHERE archived_at IS NULL` — solo si hay uniques por nombre "solo activos"

### API Endpoints
```
POST   /companies/{id}/archive    → archive (canonical)
DELETE /companies/{id}            → archive (compat; deprecable)
POST   /companies/{id}/restore    → restore (cascade where archived_by_parent_id matches)
POST   /companies/{id}/purge      → purge (requires archived_at IS NOT NULL)

POST   /companies/locations/{id}/archive → archive (canonical)
DELETE /companies/locations/{id}         → archive (compat; deprecable)
POST   /companies/locations/{id}/restore
POST   /companies/locations/{id}/purge

POST   /projects/{id}/archive     → archive (canonical)
DELETE /projects/{id}             → archive (compat; deprecable)
POST   /projects/{id}/restore
POST   /projects/{id}/purge
```

Notes:
- Frontend `apiClient.delete()` cannot send body. Use `POST /purge` for JSON confirm.

Purge body: `{"confirm_name": "exact-entity-name"}` (server-side validation)

### API Contract (status codes + filtros)
- List endpoints: `archived=active|archived|all` (default: `active`)
  - Note: projects already use `status=...` for business status filter; do not overload.
- Detail endpoints: retornan archived también (frontend muestra banner + modo read-only)
- Archive/restore: idempotentes (`200 OK` + `{message}`)
- Purge:
  - `204 No Content` si ok
  - `404 Not Found` si no existe
  - `409 Conflict` si `archived_at IS NULL`
  - `400 Bad Request` si `confirm_name` falta o no matchea
- confirm_name: match exacto con `trim()` (case-sensitive)

Idempotency + audit rule:
- Archive when already archived: do not overwrite `archived_at` / `archived_by_user_id`.
- Restore when already active: no-op.

Field mutation rules (avoid weird bugs)
- Manual archive (user action on entity): set `archived_at=now()`, `archived_by_user_id=current_user.id`, `archived_by_parent_id=NULL`.
- Cascade archive (parent archived): update child only if `archived_at IS NULL`; set `archived_at=now()`, `archived_by_user_id=current_user.id`, `archived_by_parent_id=parent.id`.
- Restore (user action): set `archived_at=NULL`, `archived_by_user_id=NULL`, `archived_by_parent_id=NULL`.

Review notes (what looks right + sharp edges)
- `archived=active|archived|all` is critical: projects already use `status` for business status; overloading would break FE filters.
- Returning `200 + {message}` for archive/restore is fine, but keep delete callers not depending on body (many FE deletes are typed `void`). `204` is also acceptable if later you want to standardize.
- `with_for_update()` is good for “persist vs archive” race; avoid holding locks during AI generation (only lock right before DB writes).
- Cascade semantics (“no clobber manual archives” + restore via `archived_by_parent_id`) is solid and keeps restoration deterministic.

### Guard
```python
def require_not_archived[T: ArchivableMixin](entity: T) -> T:
    if entity.archived_at is not None:
        raise HTTPException(409, f"{type(entity).__name__} is archived")
    return entity
```

### RBAC (permisos)
- Archive/restore:
  - Company + Location: solo `org_admin/superuser`
  - Project: `project.owner (project.user_id)` + `org_admin/superuser`
- Purge (hard delete): solo `org_admin/superuser` (Company/Location/Project)

### Write Guards (not just AI)

**Check before persist en TODAS las rutas de escritura:**
- Files: upload, delete
- Proposals: generate, delete
- project_data mutations
- Contacts: create, update, delete

Implementation default:
- Add `ActiveProjectDep` (wrap `ProjectDep` + `require_not_archived(project)`) and use it in all project write routes (`files.py`, `proposals.py`, `project_data.py`, etc.).
- Keep `ProjectDep` able to fetch archived for read-only views (detail/restore screens).
- Add `ActiveCompanyDep` + `ActiveLocationDep` for non-project write paths, same idea:
  - `ActiveCompanyDep`: load + RBAC + `archived_at IS NULL`
  - `ActiveLocationDep`: load + RBAC + `archived_at IS NULL`
  - Use in: Company update, create location; Location update, contacts CRUD; Project create must validate `location_id` via `ActiveLocationDep`.

```python
async def persist_anything_to_project(project_id: UUID, ...):
    project = await get_project(project_id)
    if project.archived_at:
        raise HTTPException(409, "Project is archived")
    # ... persist ...
```

**AI jobs específicamente:** doble check (before work + before persist) + heartbeat para jobs largos.

### Concurrencia (evitar writes después de archive)
- Adoptar `SELECT ... FOR UPDATE` (SQLAlchemy `with_for_update()`) en:
  - writes a Project (update, project_data, files, proposals)
  - archive/restore/purge de Project/Location/Company
  - cascadas (lock por lotes los hijos a modificar)

Notes:
- Locks only for short critical section; never hold during long AI generation. Re-check + lock right before persist.

### Multi-tenant hard rule (non-negotiable)
- Every load/mutation/cascade/restore/purge must scope by `organization_id = org.id`.
- Cascades: always filter children by both `organization_id` and `archived_by_parent_id` (or parent FK), never by parent_id alone.
- Validate parent belongs to org before touching children (esp. for superuser with `X-Organization-Id`).

---

## Migration Plan

1. New migration:
   - Add `archived_at`, `archived_by_user_id` to Company
   - Add `archived_at`, `archived_by_user_id`, `archived_by_parent_id` (FK companies) to Location
   - Add `archived_by_user_id`, `archived_by_parent_id` (FK locations) to Project
     - `projects.archived_at` already exists in DB via `backend/alembic/versions/20251114_0907_add_project_lifecycle_archiving.py`.
     - Migration must NOT try to re-create `archived_at`.
   - Note: Project already has `archived_at`/`is_archived`/`lifecycle_state` in DB via `backend/alembic/versions/20251114_0907_add_project_lifecycle_archiving.py`.
     Default: keep DB cols; app code uses ONLY `archived_at` semantics; ignore `is_archived` + `lifecycle_state`.
     Optional follow-up (cleanup): drop `is_archived` + `lifecycle_state` after confirming no external consumers.
   - Index: `(organization_id, archived_at)` en cada tabla

2. Update ORM models to match

## Implementation Notes (critical)

- Lock ordering (avoid deadlocks): always lock top-down (Company → Location → Project) and use a stable order inside each set (`ORDER BY id`).
- Prefer bulk updates for cascade archive/restore where possible (`UPDATE ... WHERE ...`) instead of per-row loops.
- Purge storage cleanup must collect storage keys in bulk BEFORE deleting DB rows (esp. for Company/Location).
- Purge semantics: return `404` if entity not found; return `409` if not archived; return `204` on success.
- Archived is read-only: no writes of any kind (including file/proposal deletes); cleanup is via purge only.

## Execution

Executable task list: `.opencode/plans/1769015231366-nimble-comet.tasks.md`

## Remaining Questions (non-blocking)

1. Archived in search/autocomplete? (default exclude)

## Decisions
- Archived detail reads: readable by default (read-only UX); list defaults exclude archived.
- Local storage identifiers: store relative keys only (`projects/...`, `proposals/...`), map to disk at runtime.
- Local proposal PDF URLs: `/uploads/proposals/...` (no `/uploads/uploads/...`).

---

## Follow-up Findings (post-impl review)

### Storage deletion safety (high risk)
- Purge helpers `_resolve_local_path()` allow absolute paths / traversal and can unlink outside uploads dir.
  - `backend/app/api/v1/projects.py` (local path fallback `Path(path)`)
  - `backend/app/api/v1/companies.py` (same)
- Proposal delete uses `LOCAL_UPLOADS_DIR / pdf_path`; if `pdf_path` is absolute, left side is dropped (can delete arbitrary file).
  - `backend/app/api/v1/proposals.py`
- S3 delete has no prefix allowlist; if DB/metadata contains arbitrary key, purge can delete any object in bucket.
  - `backend/app/services/s3_service.py`

### Storage hardening leftovers (post-impl)
- Defense-in-depth: enforce allowlist at low-level choke points.
  - `backend/app/services/s3_service.py` `delete_file_from_s3()` should reject non-allowlisted keys.
  - `backend/app/services/s3_service.py` `upload_file_to_s3()` (local mode) should validate key before writing.
- Local URL shape mismatch: proposal PDFs can resolve to `/uploads/uploads/proposals/...`; must be `/uploads/proposals/...`.
- Avoid validator drift: `s3_service.py` and `storage_delete_service.py` both normalize/resolve keys; keep single source.

### Frontend blockers (product correctness)
- Runtime/TS crash: `frontend/components/features/dashboard/components/project-card.tsx` uses `disabled={isDeleting}` but `isDeleting` is not defined.
  - Likely intended: `isArchiving`.
- `bun run check:ci` does not typecheck; it only runs Biome.
  - `frontend/package.json` `check:ci = biome ci ./`.
  - Next build can still fail because `next.config.mjs` has `typescript.ignoreBuildErrors = false`.
- Type errors likely exist beyond `isDeleting` (tsc output referenced): proposal report schema/type mismatch + `exactOptionalPropertyTypes` + archived filter typing in store.

## Handoff Status (what is done vs what remains)

### Done (confirmed in code)
- Storage deletion hardening implemented via `backend/app/services/storage_delete_service.py` and wired into purge + file/proposal deletes.
- DB storage identifiers now written as relative keys (no absolute paths) for new writes:
  - `backend/app/api/v1/files.py` stores `projects/...`
  - `backend/app/api/v1/proposals.py` stores `proposals/...`
- Tests added for deletion hardening: `backend/tests/test_storage_delete_service.py`.

### Remaining (must before calling "product correct")
- Local URL mismatch for proposal PDFs: eliminate `/uploads/uploads/...`; require `/uploads/proposals/...`.
  - Touch points: `backend/app/services/s3_service.py` local path mapping + `backend/app/main.py` mount.
- Defense-in-depth: enforce allowlist in `backend/app/services/s3_service.py:delete_file_from_s3()` too (not only via callers).
- Frontend crash: `frontend/components/features/dashboard/components/project-card.tsx` `isDeleting` undefined (should be `isArchiving`).
- Frontend CI gate: `frontend/package.json` `check:ci` must run `bun run build` (Biome-only is insufficient).
- Frontend TS debt: proposal report type/schema mismatch + recommendation union mismatch + exactOptionalPropertyTypes + store filter typing (no `any`).

### Suggested update for `.opencode/plans/1769015231366-nimble-comet.tasks.md`
- Mark P0 Storage deletion safety as DONE (implemented + tests).
- Add new P0 Frontend build gate + crash fixes:
  - Fix `project-card.tsx` `isDeleting`.
  - Update `frontend/package.json` `check:ci` to include `bun run build`.
- Add P0 Local URL fix: ensure local PDF URLs are `/uploads/proposals/...`.
- Add P1 TS cleanup list (proposal report ADT/schema; recommendation union; store filter typing; exactOptionalPropertyTypes).

## Next Steps (planning; do not implement yet)

### 1) Re-ground truth (what is actually broken)
- Re-run backend `make check` and capture `ty check` top ~100 lines; group by root cause.
- Verify FastAPI `ArchivedFilter` default behavior after the Query-default change (ensure endpoints still default to `active`).
- Confirm FE casing: most BE schemas inherit `BaseSchema` -> camelCase; files endpoints are snake_case.

### 2) Fix `ty` explosion via ORM annotations (chosen path)
Goal: make `instance.id` etc typed as values (`UUID`), not `Column[UUID]`.

- Minimal root fix first:
  - Edit `backend/app/models/base.py`: add `Mapped[...]` annotations for `id`, `created_at`, `updated_at` while keeping existing `Column(...)` assignments.
  - Rationale: cascades to all models inheriting Base; highest ROI.
- Re-run `ty check`; if remaining errors cluster in 2-3 models, annotate only those fields next:
  - `backend/app/models/project.py` (common: `name`, `status`, `location_id`, archive fields)
  - `backend/app/models/location.py`
  - `backend/app/models/company.py`
  - Keep change typing-only: `field: Mapped[T] = Column(...)`; avoid refactor to `mapped_column()` unless required.
- If `load_only(Project.id, ...)` still triggers, ensure attributes are typed ORM attrs (`Mapped[...]`) not raw `Column` descriptors.

### 2.5) Reduce `ty` noise: SQLAlchemy Row/Result typing
- Replace `Row` attribute access (`row.foo`) with tuple unpack or `.mappings()`.
  - Prefer tuple unpack for known shapes:
    - `rows = (await db.execute(select(Model.col))).tuples().all()` then `for (col,) in rows: ...`
  - Or use `.mappings()` for ad-hoc aggregates: `row["count"]` etc.
- Targets (highest ROI):
  - `backend/app/api/v1/projects.py` (pipeline stats; storage-path collection)
  - `backend/app/api/v1/companies.py` (location/project counts; storage-path collection)
  - `backend/scripts/cleanup_orphaned_storage.py`

### 3) Archive/purge code review follow-ups (only if confirmed by tests/logs)
- Storage purge + deletes: must not unlink outside uploads dir / delete arbitrary S3 keys.
  - Create single shared helper for validation + deletion (local + S3) and use everywhere:
    - local: reject absolute unless under allowed root; `resolve()` then `relative_to()` check; reject `..` traversal
    - S3: allowlist prefixes `("projects/", "proposals/")` (already used in cleanup script)
  - Apply to:
    - `backend/app/api/v1/projects.py` purge
    - `backend/app/api/v1/companies.py` purge
    - `backend/app/api/v1/proposals.py` delete
    - `backend/app/api/v1/files.py` delete + rollback cleanup
    - `backend/app/services/s3_service.py` `delete_file_from_s3()` as choke point
- Cascade semantics: verify restore only unarchives children archived via parent (`archived_by_parent_id`), not manually-archived.
- Background tasks: keep “check archived before persist” (already present); verify proposal status cache cannot get stuck silently.

### 3.5) Local storage layout (fix `/uploads/uploads`)
- Requirement: local proposal PDFs served at `/uploads/proposals/...`.
- Make local storage consistent (pick one; prefer A):
  - A (preferred): store proposal PDFs under `LOCAL_STORAGE_PATH/proposals/...` (remove extra `uploads/` layer); keep mount `/uploads` -> `LOCAL_STORAGE_PATH`.
  - B: mount `/uploads` -> `LOCAL_STORAGE_PATH/uploads` AND store project uploads under `LOCAL_STORAGE_PATH/uploads/projects/...`.
- Add regression check:
  - `get_presigned_url("proposals/...pdf")` returns `{BACKEND_URL}/uploads/proposals/...pdf`.

### 4) Frontend casing cleanup (low risk)
- Fix misleading comment in `frontend/components/features/dashboard/components/simplified-stats.tsx` (backend is camelCase).
- Add small note: files API remains snake_case by design (backend file schemas don’t use `BaseSchema`).

### 4.5) Frontend typecheck gate (must fix)
- CI decision: gate with `next build` (not `tsc --noEmit`).
- Make `check:ci` include Next build.
  - `frontend/package.json`: change `check:ci` to `biome ci ./ && bun run build`.
- Fix TS breakages revealed by typecheck (no `any`, no assertions).
  - `frontend/components/features/dashboard/components/project-card.tsx`: `isDeleting` -> `isArchiving` (or remove).
  - Proposal report typing: align `frontend/lib/types/proposal.ts` with UI usage OR add versioned ADT and narrow before access.
    - Hot spots: `frontend/components/features/proposals/**` using fields like `businessOpportunity`, `lca`, `technicalData`.
  - Recommendation union mismatch: standardize `INVESTIGATE` vs `INVESTIGATE FURTHER`.
    - `frontend/lib/types/proposal.ts`
    - `frontend/components/features/proposals/sidebar/decision-recommendation-card.tsx`
    - `frontend/components/features/proposals/compact-decision-header.tsx`
  - `exactOptionalPropertyTypes`: do not assign explicit `undefined` to optional props; omit the prop.
    - Example candidate: `frontend/lib/mappers/proposal-mapper.ts` for `pdfPath`.
  - Store filter typing: `frontend/lib/stores/project-store.ts` `setFilter` should be key-specific so `archived` stays `ArchivedFilter`.

### 5) Verification
- Backend: `cd backend && make check` (focus: ty).
- Backend tests: `cd backend && uv run -m pytest` (or repo standard once fixed).
- Frontend: `cd frontend && bun run check:ci` (must include typecheck).
- Frontend build: `cd frontend && bun run build` (ensures Next typecheck gate still green).

### Backend gaps (re-check status)

- Confirmed fixed (already in code):
  - `ProjectDataService.get_project_data()` allows reads for archived; writes blocked via `ActiveProjectDep` + `require_not_archived`. File: `backend/app/services/project_data_service.py`.
  - `process_file_with_ai()` skips AI work + discards results if project archived, including locked re-check before DB write. File: `backend/app/api/v1/files.py`.
- Possible policy mismatch (decide):
  - `GET /projects/{project_id}/proposals/{proposal_id}/pdf` uses `ActiveProjectDep` and can 409 even when serving cached PDF. If desired behavior is “archived fully readable but no writes”, change to allow serving cached PDF on archived while still blocking regenerate/persist.

### Frontend/contract gaps (must fix)

- Dashboard stats: no runtime mismatch found; backend returns camelCase via `BaseSchema` and FE already consumes camelCase. Only misleading FE comment suggests snake_case mapping. Files: `frontend/components/features/dashboard/components/simplified-stats.tsx`, `backend/app/schemas/common.py`, `backend/app/schemas/project.py`.
- Project type: no mismatch found; backend outputs `projectType` (alias) and FE expects `projectType`. Risk is future “cleanup” changing either side. Files: `backend/app/schemas/project.py`, `frontend/lib/project-types.ts`.
- Files API casing: backend file schemas are snake_case (do not inherit `BaseSchema`), and FE types are snake_case; keep aligned, avoid accidental camelCase refactor. Files: `backend/app/schemas/file.py`, `frontend/lib/project-types.ts`.

### Minor deviations / polish

- Purge request body is typed as `dict[str, str] | None` (OpenAPI generic). Prefer explicit Pydantic schema `{confirm_name: str}` for docs + type safety. Files: `backend/app/api/v1/projects.py`, `backend/app/api/v1/companies.py`.
- Some race windows remain (lower risk): project create checks location archived but no location lock; contacts CRUD rely on dep check but no re-lock. Consider only if bugs seen. Files: `backend/app/api/v1/projects.py`, `backend/app/api/v1/companies.py`.

## Remaining Questions (blocking)
- None

## Current Remaining Work (as-of now)

1) Backend: make `ty check` pass (agents output typing + SQLAlchemy model typing + column_property attrs)
2) Backend: confirm pytest/test runner works deterministically in real env/CI (sandbox may lie)
3) Backend: proposal PDF on archived policy = allow serving cached PDF; block regenerate/persist when archived

---

## Verification Checklist (before merge)

1. Backend: run `cd backend && make check`.
2. Frontend: run `cd frontend && bun run check:ci`.
3. Manual API spot checks (curl/postman):
   - Create project, archive it, verify: all writes (files upload/delete, proposal generate/delete, project_data update, contacts CRUD) return 409.
   - Restore, verify writes work again.
   - Purge requires archived + confirm_name exact; verify 400/404/409/204.
4. UI sanity:
   - Dashboard stats render correct numbers (fix casing/field names first).
   - Project list cards show correct type.
